{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers as l\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt'\n",
    "    , origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
    ")\n",
    "text = open(path).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600901"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200281\n",
      "200281\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for x in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[x: x + maxlen])\n",
    "    next_chars.append(text[x + maxlen])\n",
    "\n",
    "print(len(sentences))\n",
    "print(len(next_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "len(chars) # unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence, in enumerate(sentences):\n",
    "    for j, char in enumerate(sentence):\n",
    "        x[i, j, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(l.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(l.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds, temp=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temp\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train on 200281 samples\n",
      "200281/200281 [==============================] - 14s 72us/sample - loss: 1.9680\n",
      "Seed: f the obscene, with the religious feeling. the feeling that \n",
      "Temperature: 0.2\n",
      "f the obscene, with the religious feeling. the feeling that the present the sense and the all all the compations and in the in the self in the count and which is some of the self-an the self--as as the complening the some provest of the superest and the wast and the all the compless of present and provestion it could the promplent it is the compations of the mations and in the also the self-and the self-and all the sensitions of the all the interned to theTemperature: 0.5\n",
      "e self-and all the sensitions of the all the interned to the real as the such all stradicse the really and in the self-in the is the callemotion for as are of the comptions it is man it the completion to graund of the court as our that it somes preself thereby it is could to the origin to leasoly as as and in the such a such the singrations of the in the hear the pain its its not helling the periet we have are out frients and to learness and the has be notTemperature: 1.0\n",
      "t we have are out frients and to learness and the has be nothers\n",
      "the compactions \"pieverethes to been fanerhing formor, by one for estible with the duteston of this impletution youd, sweperocrach some it is the compat these with\n",
      "the gever yever hamporits, selminabless suppecesings framents. it belieps and\n",
      "cally\n",
      "aten that he. whein seated) it the reternably inthere is heirise about of mach to nat it masike in the lifilived with matices it distrutuous pures-Temperature: 1.2\n",
      "t masike in the lifilived with matices it distrutuous pures-\n",
      "us uptopiinted heowhhy agast lesifolathom yous creath, frightment for\n",
      "this methrough, necieve--in it\n",
      "powation) to which pedpelunest\n",
      "fares fortuints; all tals \"theis as never suplees he, conctuncess, ated\n",
      "graidmans, batiom him uudent reiveven heart\n",
      "purem lrate owition of theed thein that whotaen hisdrard. ism, which, to smay may cuphesion\n",
      "thir skevtited, was ever gasiout profpine\n",
      "paiv, arto the erEpoch: 2\n",
      "Train on 200281 samples\n",
      "  4480/200281 [..............................] - ETA: 16s - loss: 1.6426"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(1, 60):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "    start_i = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_i: start_i + maxlen]\n",
    "    print(f'Seed: {generated_text}')\n",
    "    for temp in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(f'Temperature: {temp}')\n",
    "        sys.stdout.write(generated_text)\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))             \n",
    "            for t, char in enumerate(generated_text):               \n",
    "                sampled[0, t, char_indices[char]] = 1.              \n",
    "            preds = model.predict(sampled, verbose=0)[0]            \n",
    "            next_index = sample(preds, temp)                 \n",
    "            next_char = chars[next_index]                           \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
