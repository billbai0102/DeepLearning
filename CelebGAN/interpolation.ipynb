{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generator import Generator\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_IN = 100\n",
    "IMG_LEN = 16\n",
    "selection = {\n",
    "    0: 'random',\n",
    "    1: 'interpolation',\n",
    "    2: 'semantic' # for example, (female - male) + child\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator().cuda()\n",
    "gen.load_state_dict(torch.load('./models/generator34.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "\n",
    "if selection[mode] == 'random':\n",
    "    # generate random seeds and move to cuda\n",
    "    latent_space_vec = torch.randn(IMG_LEN, GEN_IN, 1, 1).cuda()\n",
    "    \n",
    "elif selection[mode] == 'interpolation':\n",
    "    # load vectors\n",
    "    load_vector = np.loadtxt('vectors.txt')\n",
    "    y = np.vstack([load_vector[1], load_vector[10]])\n",
    "    xvals = np.linspace(0, 1, num=IMG_LEN)\n",
    "    # interpolation\n",
    "    sample = interp1d([0, 1], y, axis=0)\n",
    "    # generate interpolated noise/seed\n",
    "    latent_space_vec = torch.tensor(sample(xvals).reshape(IMG_LEN, GEN_IN, 1, 1), dtype=torch.float32).cuda()\n",
    "    \n",
    "elif selection[mode] == 'semantic':\n",
    "    # load vectors\n",
    "    load_vector = np.loadtxt('vectors.txt')\n",
    "    # sematically calculate new faces\n",
    "    z1 = (load_vector[0] + load_vector[6] + load_vector[8]) / 3.\n",
    "    z2 = (load_vector[1] + load_vector[2] + load_vector[4]) / 3.\n",
    "    z3 = (load_vector[3] + load_vector[4] + load_vector[6]) / 3.\n",
    "    z_new = z1 - z2 + z3\n",
    "    sample = np.zeros(shape=(IMG_LEN, GEN_IN))\n",
    "    # generate seed/noise\n",
    "    for i in range(IMG_LEN):\n",
    "        sample[i] = z_new + 0.1 * np.random.normal(-1.0, 1.0, 100)\n",
    "    latent_space_vec = torch.tensor(sample.reshape(IMG_LEN, GEN_IN, 1, 1), dtype=torch.float32).cuda()\n",
    "\n",
    "# turn off autograd\n",
    "with torch.no_grad():\n",
    "    # get output\n",
    "    viz_sample = gen(latent_space_vec)\n",
    "    # generate latent space vectors\n",
    "    viz_vector = latent_space_vec.detach().cpu().numpy().reshape(IMG_LEN, GEN_IN)\n",
    "    # save vector\n",
    "    np.savetxt('vectors.txt', viz_vector)\n",
    "    # save images\n",
    "    save_image(viz_sample, f'img_{selection[mode]}.png', nrow=IMG_LEN, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
