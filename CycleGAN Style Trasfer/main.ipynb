{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from model_api import GAN\n",
    "from dataset import CycleGANDataset\n",
    "from hyperparameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(253, Image.BICUBIC)\n",
    "    , transforms.RandomHorizontalFlip()\n",
    "    , transforms.ToTensor()\n",
    "    , transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "no_norm_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE, Image.BICUBIC)\n",
    "    , transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_ds = CycleGANDataset(transform, 'train')\n",
    "test_ds = CycleGANDataset(transform, 'test')\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(64, 64))\n",
    "# for data in train_dl:\n",
    "#     A = data['train_A'][0].numpy().transpose(1, 2, 0)\n",
    "#     B = data['train_B'][0].numpy().transpose(1, 2, 0)\n",
    "# fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(A)\n",
    "# fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(B)\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_dl.dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0/25 -- Batch: 99/6287\n",
      "Discriminator loss: 0.5588 Generator loss: 5.8076\n",
      "Time taken: 43.1236s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 199/6287\n",
      "Discriminator loss: 0.3254 Generator loss: 3.7650\n",
      "Time taken: 41.0373s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 299/6287\n",
      "Discriminator loss: 0.3046 Generator loss: 4.1096\n",
      "Time taken: 40.9823s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 399/6287\n",
      "Discriminator loss: 0.2175 Generator loss: 5.2342\n",
      "Time taken: 40.8608s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 499/6287\n",
      "Discriminator loss: 0.3886 Generator loss: 4.5586\n",
      "Time taken: 41.2698s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 599/6287\n",
      "Discriminator loss: 0.1677 Generator loss: 4.4408\n",
      "Time taken: 41.6327s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 699/6287\n",
      "Discriminator loss: 0.2684 Generator loss: 4.1226\n",
      "Time taken: 41.9847s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 799/6287\n",
      "Discriminator loss: 0.2004 Generator loss: 4.6387\n",
      "Time taken: 41.7632s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 899/6287\n",
      "Discriminator loss: 0.2750 Generator loss: 3.9126\n",
      "Time taken: 41.3017s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 999/6287\n",
      "Discriminator loss: 0.2011 Generator loss: 3.1809\n",
      "Time taken: 40.9402s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1099/6287\n",
      "Discriminator loss: 0.1856 Generator loss: 5.6855\n",
      "Time taken: 41.7952s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1199/6287\n",
      "Discriminator loss: 0.1318 Generator loss: 3.5704\n",
      "Time taken: 41.9782s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1299/6287\n",
      "Discriminator loss: 0.2262 Generator loss: 5.8957\n",
      "Time taken: 41.7663s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1399/6287\n",
      "Discriminator loss: 0.1842 Generator loss: 3.6883\n",
      "Time taken: 42.0519s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1499/6287\n",
      "Discriminator loss: 0.1998 Generator loss: 3.3943\n",
      "Time taken: 41.9080s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1599/6287\n",
      "Discriminator loss: 0.2094 Generator loss: 3.3069\n",
      "Time taken: 41.1570s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1699/6287\n",
      "Discriminator loss: 0.1789 Generator loss: 4.2791\n",
      "Time taken: 42.7918s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1799/6287\n",
      "Discriminator loss: 0.2440 Generator loss: 3.1195\n",
      "Time taken: 41.9443s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1899/6287\n",
      "Discriminator loss: 0.1845 Generator loss: 3.4151\n",
      "Time taken: 42.5604s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 1999/6287\n",
      "Discriminator loss: 0.2565 Generator loss: 3.3437\n",
      "Time taken: 41.0947s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2099/6287\n",
      "Discriminator loss: 0.2289 Generator loss: 3.2488\n",
      "Time taken: 41.3613s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2199/6287\n",
      "Discriminator loss: 0.0927 Generator loss: 3.2960\n",
      "Time taken: 41.1769s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2299/6287\n",
      "Discriminator loss: 0.2490 Generator loss: 2.5433\n",
      "Time taken: 41.2605s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2399/6287\n",
      "Discriminator loss: 0.1892 Generator loss: 3.1376\n",
      "Time taken: 41.8237s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2499/6287\n",
      "Discriminator loss: 0.2434 Generator loss: 3.0167\n",
      "Time taken: 42.3070s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2599/6287\n",
      "Discriminator loss: 0.1777 Generator loss: 2.8784\n",
      "Time taken: 42.0865s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2699/6287\n",
      "Discriminator loss: 0.1668 Generator loss: 4.1913\n",
      "Time taken: 41.5982s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2799/6287\n",
      "Discriminator loss: 0.3574 Generator loss: 4.6485\n",
      "Time taken: 41.6003s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2899/6287\n",
      "Discriminator loss: 0.1697 Generator loss: 3.6246\n",
      "Time taken: 42.0090s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 2999/6287\n",
      "Discriminator loss: 0.1650 Generator loss: 4.4928\n",
      "Time taken: 41.5674s\n",
      "\n",
      "Epoch: 0/25 -- Batch: 3099/6287\n",
      "Discriminator loss: 0.2954 Generator loss: 3.2887\n",
      "Time taken: 42.5291s\n"
     ]
    }
   ],
   "source": [
    "gan.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
